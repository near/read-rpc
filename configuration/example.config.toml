### General configuration for NEAR ReadRPC
[general]

## Chain ID: testnet or mainnet
chain_id = "mainnet"

## Near network rpc url
## Using for proxying some requests to near network and to handle finality block
near_rpc_url = "https://beta.rpc.mainnet.near.org"

## Referer header value
## We want to set a custom referer to let NEAR JSON RPC nodes know that we are a read-rpc instance
## Default value is "http://read-rpc.local"
#referer_header_value = "http://read-rpc.local"

## near network archival rpc url
## Using under the hood in near network rpc
## Not needed for regular users.
## Please, don't uncoment this parameter or use same as near_rpc_url
## default value is None
#near_archival_rpc_url = "https://beta.rpc.mainnet.near.org"

## redis url using for pub/sub optimistic_block and final_block
## from near_state_indexer to rpc_server
## Default value is redis://127.0.0.1/
#redis_url = "redis://127.0.0.1/"

### Rpc server general configuration
[general.rpc_server]

## Port for RPC server
## Default port is 8000
#server_port = 8000

## Max gas burnt for contract function call
## We allow to use max gas bunt to run contract function call
## Default value is 300_000_000_000_000
#max_gas_burnt = 300_000_000_000_000

## Contract code cache in gigabytes
## By default we use 0.25 gigabyte (256MB or 268_435_456 bytes)
#contract_code_cache_size = 0.25

## Block cache size in gigabytes
## By default we use 0.125 gigabyte (128MB or 134_217_728 bytes)
## One cache_block size is â‰ˆ 96 bytes
## In 128MB we can put 1_398_101 cache_blocks
#block_cache_size = 0.125

## How many requests we should check for data consistency
## By default we use 100% of requests
## If you want to check 1% of requests, you should set 1
## thet means for every method calls will be checked every 100th request
#shadow_data_consistency_rate = 100

### Tx indexer general configuration
[general.tx_indexer]

## Indexer ID to handle meta data about the instance
## Unique indexer ID
## Default value is "tx-indexer"
## If you run multiple instances of the indexer, you should change this value for each instance
#indexer_id = "tx-indexer"

## Port for metrics server
## By default it 8080 for tx-indexer and 8081 for state-indexer
#metrics_server_port = 8080

## To restore cache from db we use smart range blocks
## Regular transaction takes some blocks to be finalized
## We don't need to restore too old transactions for the indexer because we will probably never be able to reassemble them.
## We use a range of 1000 blocks for our peace of mind. We also leave the option to increase or decrease this range
#cache_restore_blocks_range = 1000

### State indexer general configuration
[general.state_indexer]

## Indexer ID to handle meta data about the instance
## Unique indexer ID
## Default value is "state-indexer"
## If you run multiple instances of the indexer, you should change this value for each instance
#indexer_id = "state-indexer"

## Port for metrics server
## By default it 8080 for tx-indexer and 8081 for state-indexer
#metrics_server_port = 8081

## Concurrency for state-indexer
## Default value is 1
#concurrency = 1

### Near state indexer general configuration
[general.near_state_indexer]

## Port for metrics server
## By default it 8082
#metrics_server_port = 8082

## Concurrency for state-indexer
## Default value is 1
#concurrency = 1

### Tracking acconunts and state changes configuration
[rightsizing]

## Accounts to track. By default we track all accounts.
## You can specify a list of accounts to track.
## tracked_accounts = ["test.near"]
#tracked_accounts = []

## State changes to track. By default we track all state changes.
## You can specify a list of state changes to track.
## Possible values: "state", "access_key", "contract_code"
## "accounts" are tracked from the `tracked_accounts` section
#tracked_changes = ["state", "access_key", "contract_code"]

### Lake framework configuration
[lake_config]

## Lake framework AWS access key id
aws_access_key_id = "${AWS_ACCESS_KEY_ID}"

## Lake framework AWS secret access key
aws_secret_access_key = "${AWS_SECRET_ACCESS_KEY}"

## Lake framework AWS default region
aws_default_region = "eu-central-1"

## Lake framework bucket name
aws_bucket_name = "near-lake-data-mainnet"

[tx_details_storage]
## Transaction details are stored in the S3-compatibe object storage (Google Cloud Storage by default)
## You can use any S3-compatible object storage
## Storage Access Key ID
aws_access_key_id = "${TX_AWS_ACCESS_KEY_ID}"

# Storage Secret Access Key
aws_secret_access_key = "${TX_AWS_SECRET_ACCESS_KEY}"

# Storage Region
aws_default_region = "eu-central-1"

# Storage Bucket Name
aws_bucket_name = "readrpc-tx-details"

# Storage Endpoint
# Default value is "https://storage.googleapis.com" pointing to Google Cloud Storage
# You can use any S3-compatible object storage, e.g. "https://s3.amazonaws.com"
# or MinIO "http://127.0.0.1:9000"
aws_endpoint = "https://storage.googleapis.com"

## Database configuration
[database]

## Database connection string
## You can use database connection URL
## postgresql://{user}:{password}@localhost:5432/{db_name}
database_url = "postgresql://postgres:password@localhost:5432/near-indexer"

## Database shards
## You can use multiple database shards
## Each shard should have a unique shard_id
## You can use the same database_url for all shards
## or use different database_url for each shard
## If you use different database_url for each shard, you should create a separate database for each shard
[[database.shards]]
shard_id = 0
database_url = "${SHARD_0_DATABASE_URL}"

[[database.shards]]
shard_id = 1
database_url = "${SHARD_1_DATABASE_URL}"

[[database.shards]]
shard_id = 2
database_url = "${SHARD_2_DATABASE_URL}"

[[database.shards]]
shard_id = 3
database_url = "${SHARD_3_DATABASE_URL}"

[[database.shards]]
shard_id = 4
database_url = "${SHARD_4_DATABASE_URL}"

[[database.shards]]
shard_id = 5
database_url = "${SHARD_5_DATABASE_URL}"
